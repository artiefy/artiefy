# Sistema de Embeddings Vectoriales

## Descripci√≥n General

Este sistema permite generar embeddings vectoriales (representaciones matem√°ticas) del contenido de los cursos para habilitar b√∫squedas sem√°nticas inteligentes. Utiliza OpenAI's `text-embedding-3-small` que genera vectores de 1536 dimensiones optimizados para balance velocidad/precisi√≥n.

## Arquitectura

### Componentes Principales

1. **Schema Drizzle** (`src/server/db/schema/embeddings.ts`)
   - Tabla `document_embeddings`: almacena chunks con sus embeddings
   - Tabla `embeddingProcessingLog`: registra el progreso del procesamiento
   - √çndice HNSW para b√∫squedas vectoriales r√°pidas

2. **Procesador** (`src/lib/embeddings/processor.ts`)
   - `generateEmbedding()`: crea embedding de texto con OpenAI
   - `processDocument()`: divide documento en chunks y genera embeddings
   - `generateQueryEmbedding()`: embedding para queries de b√∫squeda
   - `searchDocuments()`: b√∫squeda por similitud coseno

3. **Base de Datos** (`src/lib/embeddings/search.ts`)
   - `saveDocumentEmbeddings()`: guarda embeddings en BD
   - `searchDocumentEmbeddings()`: b√∫squeda vectorial en PostgreSQL
   - `getCourseDocuments()`: obtiene documentos de un curso
   - `getEmbeddingsStats()`: estad√≠sticas de uso

4. **API Routes**
   - `POST /api/embeddings/generate`: procesa documento y genera embeddings
   - `POST /api/embeddings/search`: busca documentos similares
   - `GET /api/embeddings/documents`: lista documentos procesados

5. **Componente UI** (`src/components/embeddings/EmbeddingsGenerator.tsx`)
   - Bot√≥n interactivo para generar embeddings
   - Muestra estad√≠sticas de procesamiento
   - Manejo de errores y feedback visual

## Configuraci√≥n Requerida

### 1. Variables de Entorno

Ya est√°n configuradas en `src/env.ts`:

```typescript
OPENAI_API_KEY: z.string().min(1) // Requerida
```

### 2. Base de Datos PostgreSQL

Requiere pgvector extension. Ejecutar migraci√≥n:

```bash
npm run db:generate
npm run db:migrate
```

O ejecutar manualmente en Neon:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### 3. Dependencias

Ya incluidas en `package.json`:

- `openai`: ^4.0.0
- `@neondatabase/serverless`: ^1.0.2
- `drizzle-orm`: √∫ltima versi√≥n

## Uso

### Desde la UI

1. Ir a Dashboard > Super Admin > Cursos > [Seleccionar Curso]
2. Hacer click en tab "üß† Embeddings"
3. Hacer click en bot√≥n "üöÄ Generar Embeddings"
4. Esperar confirmaci√≥n y ver estad√≠sticas

### Desde CLI

**Generar embeddings para un curso espec√≠fico:**

```bash
npm run embeddings:regen -- --courseId=123
```

**Regenerar para todos los cursos:**

```bash
npm run embeddings:regen -- --all
```

## Flujo de Procesamiento

```
Documento (PDF/DOCX/TXT)
       ‚Üì
Extracci√≥n de Texto
       ‚Üì
Normalizaci√≥n
       ‚Üì
Chunking (1000 tokens, 200 overlap)
       ‚Üì
Generaci√≥n de Embeddings (OpenAI)
       ‚Üì
Guardado en PostgreSQL con pgvector
       ‚Üì
Indexaci√≥n HNSW
```

## Costos y Estimaciones

**Modelo:** text-embedding-3-small
**Precio:** $0.020 por 1M tokens

Ejemplos:

- 10,000 tokens = $0.0002 (0.02¬¢)
- 100,000 tokens = $0.002 (0.2¬¢)
- 1,000,000 tokens = $0.02 (2¬¢)

## B√∫squeda Sem√°ntica

Una vez procesados los embeddings, puedes hacer b√∫squedas:

```typescript
// Desde la API
POST /api/embeddings/search
{
  "courseId": "123",
  "query": "¬øC√≥mo funciona el algoritmo de clasificaci√≥n?",
  "topK": 5,
  "threshold": 0.5
}
```

Respuesta:

```json
{
  "success": true,
  "query": "¬øC√≥mo funciona...",
  "results": [
    {
      "content": "El algoritmo de clasificaci√≥n...",
      "similarity": 0.92,
      "chunkIndex": 0,
      "source": "course-123",
      "metadata": {...}
    }
  ]
}
```

## Estructura de Archivos

```
src/
‚îú‚îÄ‚îÄ lib/embeddings/
‚îÇ   ‚îú‚îÄ‚îÄ processor.ts      # Procesamiento y generaci√≥n de embeddings
‚îÇ   ‚îú‚îÄ‚îÄ search.ts         # B√∫squeda y base de datos
‚îÇ   ‚îî‚îÄ‚îÄ utils.ts          # Utilidades (chunking, normalizaci√≥n)
‚îú‚îÄ‚îÄ server/db/schema/
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.ts     # Schema Drizzle
‚îú‚îÄ‚îÄ app/api/embeddings/
‚îÇ   ‚îú‚îÄ‚îÄ generate/route.ts # API para generar
‚îÇ   ‚îú‚îÄ‚îÄ search/route.ts   # API para buscar
‚îÇ   ‚îî‚îÄ‚îÄ documents/route.ts # API para listar
‚îú‚îÄ‚îÄ components/embeddings/
‚îÇ   ‚îî‚îÄ‚îÄ EmbeddingsGenerator.tsx # Componente UI
‚îî‚îÄ‚îÄ app/dashboard/super-admin/.../CourseDetail.tsx # Integraci√≥n

scripts/
‚îî‚îÄ‚îÄ regen-embeddings.ts  # Script CLI para regenerar
```

## Troubleshooting

### Error: "pgvector extension not enabled"

Soluci√≥n: Ejecutar `CREATE EXTENSION IF NOT EXISTS vector;` en Neon

### Error: "Invalid OpenAI API key"

Soluci√≥n: Verificar que `OPENAI_API_KEY` est√° correctamente configurada en `.env`

### Procesamiento lento

- Los chunks grandes requieren m√∫ltiples llamadas a OpenAI
- Se aplica rate limiting de 100ms entre requests
- Cursos con >100,000 tokens pueden tomar varios minutos

### Errores de memoria

- Limitar tama√±o de chunks a m√°ximo 1000 tokens
- Procesar por lotes si hay muchos documentos

## Optimizaciones Futuras

1. **Batch Processing**: procesar m√∫ltiples chunks en paralelo
2. **Caching**: cachear embeddings frecuentes
3. **Reranking**: agregar modelos de reranking para mejorar relevancia
4. **Filtros**: permitir b√∫squeda h√≠brida (sem√°ntica + keywords)
5. **Analytics**: tracking de consultas y uso de tokens

## Referencias

- [OpenAI Embeddings API](https://platform.openai.com/docs/api-reference/embeddings)
- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Drizzle ORM](https://orm.drizzle.team/)
- [Semantic Search Best Practices](https://www.pinecone.io/learn/semantic-search/)
